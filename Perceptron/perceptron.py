# -*- coding: utf-8 -*-
"""Perceptron

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zJywjCNqFmcWUioB3Ndj961rYE2YAMC1

# Perceptron
"""

# Import Libraries
import pandas as pd
import numpy as np

# For pre-made imported perceptron:
# from sklearn.linear_model import Perceptron

# Load the training data
train_data = np.genfromtxt('train.csv', delimiter=',')
X_train = train_data[:, :-1]  # Extract features
y_train = train_data[:, -1]  # Extract labels

# Load the test data
test_data = np.genfromtxt('test.csv', delimiter=',')
X_test = test_data[:, :-1]  # Extract features
y_test = test_data[:, -1]  # Extract labels

# Set the maximum number of epochs
T = 10

"""###Pre-Made Imported Perceptron"""

# # Initialize the perceptron model
# perceptron = Perceptron(max_iter=T)

# # Train the perceptron model on the training data
# perceptron.fit(X_train, y_train)

# # Get the learned weight vector
# weights = perceptron.coef_[0]  # Extract the first weight vector
# print("Learned weight vector:", weights)

# # Predict the labels for the test data
# y_pred = perceptron.predict(X_test)

# # Calculate the average prediction error
# error_rate = np.mean(y_pred != y_test)
# print("Average prediction error:", error_rate)

"""##Standard Perceptron"""

# Implement the standard Perceptron. Set the maximum number of
# epochs T to 10. Report your learned weight vector, and the average prediction
# error on the test dataset.

def predict(X_test, weights):
    """Predicts the labels for the test data.

    Args:
        X_test (numpy.ndarray): Test data features.
        weights (numpy.ndarray): Learned weight vector.

    Returns:
        numpy.ndarray: Predicted labels.
    """

    predictions = np.dot(X_test, weights) > 0
    return predictions

def train_perceptron(X_train, y_train, T):
    """Trains the perceptron model using the training data.

    Args:
        X_train (numpy.ndarray): Training data features.
        y_train (numpy.ndarray): Training data labels.
        T (int): Maximum number of epochs.

    Returns:
        numpy.ndarray: Learned weight vector.
    """

    # Initialize all weights to zero.
    weights = np.zeros(X_train.shape[1])

    # Training loop, for each training example ...
    for _ in range(T):

        # Predict and record errors
        predictions = predict(X_train, weights)
        errors = predictions != y_train

        # Update weights based on errors
        for i in range(X_train.shape[0]):
            if errors[i]:
                weights += errors[i] * X_train[i]

    return weights

# Train the perceptron model
weights = train_perceptron(X_train, y_train, T)
print("Standard Perceptron Learned weight vector:", weights)

# Predict the labels for the test data
y_pred = predict(X_test, weights)

# Calculate the average prediction error
error_rate = np.mean(y_pred != y_test)
print("Standard Perceptron Average prediction error:", error_rate)

"""##Voted Perceptron"""

# Implement the voted Perceptron. Set the maximum number of epochs
# T to 10. Report the list of the distinct weight vectors and their counts â€” the
# number of correctly predicted training examples. Using this set of weight vectors
# to predict each test example. Report the average test error.

def voted_perceptron(X_train, y_train, T):
    """Implements the voted perceptron algorithm.

    Args:
        X_train (numpy.ndarray): Training data features.
        y_train (numpy.ndarray): Training data labels.
        T (int): Maximum number of epochs.

    Returns:
        List of (weight_vector, count) pairs.
    """

    # Initialize weight vector and count vector
    weights = np.zeros(X_train.shape[1])
    counts = np.zeros(1)

    # For each epoch ...
    for _ in range(T):
        # Iterate over training examples, for each training example...
        for i in range(X_train.shape[0]):
            x_i = X_train[i]
            y_i = y_train[i]

            # Update weight vector and count vector if necessary
            if y_i * np.dot(weights, x_i) <= 0:
                weights += y_i * x_i
                counts[0] += 1
            # Otherwise increase counts by one.
            else:
                counts = np.append(counts, 1)

    # Return list of (weight_vector, count) pairs
    weight_count_pairs = []
    for i in range(len(counts)):
        if counts[i] > 0:
            weight_count_pairs.append((weights.copy(), counts[i]))

    return weight_count_pairs

def predict(x, weight_count_pairs):
    """Predicts the label for a given test example.

    Args:
        x (numpy.ndarray): Test example features.
        weight_count_pairs (list): List of (weight_vector, count) pairs.

    Returns:
        Predicted label.
    """

    # Compute the weighted sum of sign(w_i^T x)
    weighted_sum = 0
    for weight_vector, count in weight_count_pairs:
        sign_product = count * np.sign(np.dot(weight_vector, x))
        weighted_sum += sign_product

    return np.sign(weighted_sum)

# Train the voted perceptron model
weights_and_counts = voted_perceptron(X_train, y_train, T)


seen_weights = set()

# Report the list of distinct weight vectors and their counts
print("List of distinct weight vectors and their counts:")
for weight_vector, count in weights_and_counts:
    weight_vector_tuple = tuple(weight_vector)
    if weight_vector_tuple not in seen_weights:
        print(f"Weight vector: {weight_vector}, Count: {count}")
        seen_weights.add(weight_vector_tuple)

# Predict the labels for the test data
y_pred = []
for x_test in X_test:
    prediction = predict(x_test, weights_and_counts)
    y_pred.append(prediction)

# Calculate the average test error
error_rate = np.mean(y_pred != y_test)
print("Voted Perceptron Average test error:", error_rate)

"""##Average Perceptron"""

# Implement the average Perceptron. Set the maximum number of
# epochs T to 10. Report your learned weight vector. Comparing with the list of
# weight vectors from (b), what can you observe? Report the average prediction
# error on the test data.

def train_averaged_perceptron(X_train, y_train, T):
    """Trains the averaged perceptron model using the training data.

    Args:
        X_train (numpy.ndarray): Training data features.
        y_train (numpy.ndarray): Training data labels.
        T (int): Maximum number of epochs.

    Returns:
        numpy.ndarray: Averaged weight vector.
    """

    weights = np.zeros(X_train.shape[1])  # Initialize weights to zeros
    a = np.zeros(X_train.shape[1])  # Initialize averaged weight vector

    # Training loop, for each training epoch ...
    for _ in range(T):
        # For each training example (xi, yi) in D ...
        for xi, yi in zip(X_train, y_train):
            if yi * np.dot(weights, xi) <= 0:  # Misclassification
                weights += yi * xi  # Update weights

            # Update averaged weight vector
            a += weights

    # Return the averaged weight vector
    return a / T

def predict(X_test, averaged_weights):
    """Predicts the labels for the test data using the averaged perceptron.

    Args:
        X_test (numpy.ndarray): Test data features.
        averaged_weights (numpy.ndarray): Averaged weight vector.

    Returns:
        numpy.ndarray: Predicted labels.
    """

    predictions = np.dot(averaged_weights, X_test.T) > 0
    return predictions



# Train the averaged perceptron model
averaged_weights = train_averaged_perceptron(X_train, y_train, T)

# Print the learned weight vector
print("Learned weight vector:")
print(averaged_weights)

# Evaluate prediction error on the test data
y_pred = predict(X_test, averaged_weights)
error_rate = np.mean(y_pred != y_test)
print("Averaged Perceptron Average test error: ", error_rate)