# -*- coding: utf-8 -*-
"""Perceptron

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zJywjCNqFmcWUioB3Ndj961rYE2YAMC1

# Perceptron
"""

# Import Libraries
import pandas as pd
import numpy as np

# For pre-made imported perceptron:
# from sklearn.linear_model import Perceptron

print()
print()
print()

# Load the training data
train_data = np.genfromtxt('train.csv', delimiter=',')
X_train = train_data[:, :-1]  # Extract features
y_train = train_data[:, -1]  # Extract labels

# Load the test data
test_data = np.genfromtxt('test.csv', delimiter=',')
X_test = test_data[:, :-1]  # Extract features
y_test = test_data[:, -1]  # Extract labels

# Set the maximum number of epochs
T = 10

"""###Pre-Made Imported Perceptron"""

# # Initialize the perceptron model
# perceptron = Perceptron(max_iter=T)

# # Train the perceptron model on the training data
# perceptron.fit(X_train, y_train)

# # Get the learned weight vector
# weights = perceptron.coef_[0]  # Extract the first weight vector
# print("Learned weight vector:", weights)

# # Predict the labels for the test data
# y_pred = perceptron.predict(X_test)

# # Calculate the average prediction error
# error_rate = np.mean(y_pred != y_test)
# print("Average prediction error:", error_rate)

"""##Standard Perceptron"""

# Implement the standard Perceptron. Set the maximum number of
# epochs T to 10. Report your learned weight vector, and the average prediction
# error on the test dataset.

def predict(X_test, weights):
    """Predicts the labels for the test data.

    Args:
        X_test (numpy.ndarray): Test data features.
        weights (numpy.ndarray): Learned weight vector.

    Returns:
        numpy.ndarray: Predicted labels.
    """

    predictions = np.dot(X_test, weights) > 0
    return predictions

def train_perceptron(X_train, y_train, T):
    """Trains the perceptron model using the training data.

    Args:
        X_train (numpy.ndarray): Training data features.
        y_train (numpy.ndarray): Training data labels.
        T (int): Maximum number of epochs.

    Returns:
        numpy.ndarray: Learned weight vector.
    """

    # Initialize all weights to zero.
    weights = np.zeros(X_train.shape[1])

    # Training loop, for each training example ...
    for _ in range(T):

        # Predict and record errors
        predictions = predict(X_train, weights)
        errors = predictions != y_train

        # Update weights based on errors
        for i in range(X_train.shape[0]):
            if errors[i]:
                weights += errors[i] * X_train[i]

    return weights

# Train the perceptron model
weights = train_perceptron(X_train, y_train, T)
print("Standard Perceptron Learned weight vector:", weights)

# Predict the labels for the test data
y_pred = predict(X_test, weights)

# Calculate the average prediction error
error_rate = np.mean(y_pred != y_test)
print("Standard Perceptron Average prediction error:", error_rate)

"""##Voted Perceptron"""

# Implement the voted Perceptron. Set the maximum number of epochs
# T to 10. Report the list of the distinct weight vectors and their counts â€” the
# number of correctly predicted training examples. Using this set of weight vectors
# to predict each test example. Report the average test error.

# Finds the sign of the variable.
def sign(x):
    if x > 0:
        return 1
    else:
        return -1

def voted_perceptron(X, y, T):
    """Trains the perceptron model using the training data.

    Args:
        X (numpy.ndarray): Training data features.
        y (numpy.ndarray): Training data labels.
        T (int): Maximum number of epochs.

    Returns:
        numpy.ndarray: Learned weight vector.
    """
    # Number of features
    d = X.shape[1]

    # Weight vector w to zero vector.
    w = np.zeros(d)

    # Keeps track of history.
    w_history = []

    # For each epoch...
    for t in range(T):

        # For each training example...
        for i in range(X.shape[0]):
            # If the training example is not correct...
            if sign(np.dot(w, X[i])) != y[i]:
                # Update weights.
                w += y[i] * X[i]

        # Append the weights.
        w_history.append(w.copy())

    return w_history

# Predicts the value given weights.
def predict(X, w):
    y_pred = []
    for x in X:
        y_pred.append(sign(np.dot(w, x)))

    return y_pred

# Train the voted perceptron
w_history = voted_perceptron(X_train, y_train, T=10)

# Predict the test examples
y_pred = predict(X_test, w_history[-1])

# Calculate the average test error
error = np.mean(y_pred != y_test)
print("Average test error:", error)

# Print the distinct weight vectors and their counts
unique_w, counts = np.unique(w_history, axis=0, return_counts=True)
for w, count in zip(unique_w, counts):
    print(w, count)

"""##Average Perceptron"""

# Implement the average Perceptron. Set the maximum number of
# epochs T to 10. Report your learned weight vector. Comparing with the list of
# weight vectors from (b), what can you observe? Report the average prediction
# error on the test data.

def train_averaged_perceptron(X_train, y_train, T):
    """Trains the averaged perceptron model using the training data.

    Args:
        X_train (numpy.ndarray): Training data features.
        y_train (numpy.ndarray): Training data labels.
        T (int): Maximum number of epochs.

    Returns:
        numpy.ndarray: Averaged weight vector.
    """

    weights = np.zeros(X_train.shape[1])  # Initialize weights to zeros
    a = np.zeros(X_train.shape[1])  # Initialize averaged weight vector

    # Training loop, for each training epoch ...
    for _ in range(T):
        # For each training example (xi, yi) in D ...
        for xi, yi in zip(X_train, y_train):
            if yi * np.dot(weights, xi) <= 0:  # Misclassification
                weights += yi * xi  # Update weights

            # Update averaged weight vector
            a += weights

    # Return the averaged weight vector
    return a / T

def predict(X_test, averaged_weights):
    """Predicts the labels for the test data using the averaged perceptron.

    Args:
        X_test (numpy.ndarray): Test data features.
        averaged_weights (numpy.ndarray): Averaged weight vector.

    Returns:
        numpy.ndarray: Predicted labels.
    """

    predictions = np.dot(averaged_weights, X_test.T) > 0
    return predictions



# Train the averaged perceptron model
averaged_weights = train_averaged_perceptron(X_train, y_train, T)

# Print the learned weight vector
print("Learned weight vector:")
print(averaged_weights)

# Evaluate prediction error on the test data
y_pred = predict(X_test, averaged_weights)
error_rate = np.mean(y_pred != y_test)
print("Averaged Perceptron Average test error: ", error_rate)