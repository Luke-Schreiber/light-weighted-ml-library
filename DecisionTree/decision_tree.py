# -*- coding: utf-8 -*-
"""Decision Tree

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h7B5n4hWs_bR-Klr-NUwvX2AuscrOuq1
"""

# Imports
import csv
import pandas as pd
import numpy as np

def prompt_user_preference():
  """Prompts the user to type in their preference of either option one: information gain, option two: majority error or option three: gini index.

  Returns:
    A string representing the user's preference.
  """

  print("Please select your preferred attribute selection measure:")
  print("1. Information Gain")
  print("2. Majority Error")
  print("3. Gini Index")

  user_preference = input("Enter your selection (1, 2, or 3): ")

  while user_preference not in ["1", "2", "3"]:
    print("Invalid selection. Please enter a valid selection.")
    user_preference = input("Enter your selection (1, 2, or 3): ")

  return user_preference

def prompt_user_for_max_tree_depth():
  """Prompts the user to type in their preference of maximum tree depth (either 1, 2, 3, 4, 5 or 6).

  Returns:
    An integer representing the user's preference.
  """

  print("Please select the maximum tree depth:")
  print("1, 2, 3, 4, 5, or 6")

  max_tree_depth = input("Enter your selection: ")

  while max_tree_depth not in ["1", "2", "3", "4", "5", "6"]:
    print("Invalid selection. Please enter a valid selection.")
    max_tree_depth = input("Enter your selection: ")

  return int(max_tree_depth)

attribute_selector = prompt_user_preference()
max_tree_depth = prompt_user_for_max_tree_depth()

def read_csv_to_list_of_dicts(filename, column_categories):
  """Reads a CSV file into a list of dictionaries, with hard-coded column categories.

  Args:
    filename: The path to the CSV file.
    column_categories: A list of the column categories.

  Returns:
    A list of dictionaries, where each dictionary maps the column categories to the
    corresponding values.
  """

  # Open the CSV file.
  with open(filename, "r") as f:

    # Create a list of dictionaries to store the data.
    data = {}

    # The Key for the data dictionary.
    lineNumber = 0

    # Iterate over the rows in the CSV file.
    for line in f:

      # Increasing the key for every row.
      lineNumber = lineNumber + 1
      # Create a dictionary to store the data for the current row.
      row_dict = {}

      terms = line.strip().split(',')

      # Iterate over the column categories and add the corresponding values to the
      # dictionary.
      for i in range(len(column_categories)):
          row_dict[column_categories[i]] = terms[i]

      # Append the dictionary to the list of dictionaries.
      data[lineNumber] = row_dict

  return data

def giniIndex(data):
  return 0

def majorityError(data):
  return 0

def entropy(data):
  return np.random

def gain(data):
  data_list = list(data)
  if (data_list[0] == "med"):
    return 1
  else:
    return 0

class Node:
  """A node in an ID3 decision tree."""

  def __init__(self, feature=None, children=None, value=None):
    """Initializes a new node.

    Args:
      feature: The feature to split on at this node.
      children: A dictionary of child nodes, where the key is the value of the
        feature and the value is the child node.
      value: The value of the target variable at this node.
    """

    self.feature = feature
    self.children = children
    self.value = value

def build_id3_tree(data, attributes):

  # Base case
  if len(data) == 0 or len(attributes) == 0:
     return Node(np.argmax(np.bincount(data[target_name])))

  # Calculate the information gain of each attribute.
  gains = []
  for attribute in attributes:
    gains.append(gain(entry[attribute] for entry in data.values()))

  # Find the attribute with the highest information gain.
  best_attribute = attributes[np.argmax(gains)]

  # Find the unique values of the best attribute
  best_attribute_column = (entry[best_attribute] for entry in data.values())
  uniques = np.unique(list(best_attribute_column))

  # Split the datasets by the unique values.
  subsets = {}
  for value in uniques:
    subset = {k: v for k, v in data.items() if v[best_attribute] == value}
    subsets[value] = subset

  # Recursively build a decision tree for each subset.
  children = {}
  for value, subset in subsets.items():
    children[value] = build_id3_tree(subset, attributes - {best_attribute})

  # Return the root node of the decision tree.
  return Node(best_attribute, children)

def predict(tree, data):
  """Predicts the class label of a new data point."""
  node = tree
  while True:
    if not isinstance(node, Node):
      return node
    feature = node.feature
    value = data[feature]1
    node = node.children[value]

def array_matches(array1, array2):
  count = 0
  for i in range(len(array1)):
    if array1[i] == array2[i]:
      count += 1
  return count

def evaluate(tree, data, target_name):
  """Evaluates the ID3 decision tree."""
  predictions = []
  for i in range(len(data)):
    predictions.append(predict(tree, data[i+1]))

  actual_labels = list((entry[target_name] for entry in data.values()))
  accuracy = array_matches(predictions, actual_labels) / len(data)
  return accuracy

# Load the data.
column_categories = ["buying", "maint", "doors", "persons", "lug_boot", "safety", "label"]
label_column = "label"
trainData = read_csv_to_list_of_dicts("train.csv", column_categories)
testData = read_csv_to_list_of_dicts("test.csv", column_categories)
evaluationData = testData


# Calculate Sample entropy, ME, and GI.
sample = 0;
label_values = [entry['label'] for entry in trainData.values()]
if (attribute_selector == "1"):
  sample = entropy(label_values)
if (attribute_selector == "2"):
  sample = majorityError(label_values)
if (attribute_selector == "3"):
  sample = giniIndex(label_values)

# Get Attributes of Train Data (Remove Label Column)
trainDataAttributes = ["buying", "maint", "doors", "persons", "lug_boot", "safety"]

# Build the ID3 decision tree.
#tree = build_id3_tree(trainData, trainDataAttributes)

# Evaluate the ID3 decision tree.
#accuracy = evaluate(tree, evaluationData, label_column)

# Print the accuracy.
print('Accuracy:', accuracy)